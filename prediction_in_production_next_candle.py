#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
prediction_in_production_next_candle.py (Ù†Ø³Ø®Ù‡â€ŒÛŒ Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ø´Ø¯Ù‡)

Ø¯Ù¾Ù„ÙˆÛŒ Ø¢ÙÙ„Ø§ÛŒÙ†/Ù„Ø§ÛŒÙˆ Ø¨Ø§ Ù…Ù†Ø·Ù‚ Â«Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ú©Ù†Ø¯Ù„ Ø¨Ø¹Ø¯ÛŒ (t â†’ t+1)Â»:

- Ú˜Ù†Ø±Ø§ØªÙˆØ± (ÛŒØ§ MT4) ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ *_live.csv Ø±Ø§ ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
- Ø§ÛŒÙ† Ø§Ø³Ú©Ø±ÛŒÙ¾Øª:
    1) Ø§Ø² XAUUSD_M30_live.csv Ø²Ù…Ø§Ù† Ø¢Ø®Ø±ÛŒÙ† Ú©Ù†Ø¯Ù„ Ø±Ø§ Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯ (ts_now).
    2) Ø±ÙˆÛŒ CSVÙ‡Ø§ÛŒ Ø®Ø§Ù… (XAUUSD_M30/M15/M5/H1) ØªØ§ ts_now ÙÛŒÚ†Ø± Ù…ÛŒâ€ŒØ³Ø§Ø²Ø¯.
    3) Ø¨Ø§ predict_drop_last=TrueØŒ Ø¢Ø®Ø±ÛŒÙ† Ø³Ø·Ø± Ù†Ø§Ù¾Ø§ÛŒØ¯Ø§Ø± Ø±Ø§ Ø­Ø°Ù Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    4) Ø¢Ø®Ø±ÛŒÙ† Ø³Ø·Ø± Ù¾Ø§ÛŒØ¯Ø§Ø± ÙÛŒÚ†Ø± Ø±Ø§ Ø¨Ù‡ Ù…Ø¯Ù„ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ùˆ Ø¬Ù‡Øª Ú©Ù†Ø¯Ù„ Ø¨Ø¹Ø¯ÛŒ Ø±Ø§ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    5) Ø¬ÙˆØ§Ø¨ Ø±Ø§ Ø¯Ø± answer.txt Ù…ÛŒâ€ŒÙ†ÙˆÛŒØ³Ø¯ ØªØ§ MT4 Ø¨Ø®ÙˆØ§Ù†Ø¯.

Ø¯Ø± Ù„Ø§ÛŒÙˆ:
- Ù‡ÛŒÚ† Feature Selection Ø§Ø¬Ø±Ø§ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯.
- ÙÙ‚Ø· Ø§Ø² train_window_cols Ø°Ø®ÛŒØ±Ù‡â€ŒØ´Ø¯Ù‡ Ø¯Ø± best_model.pkl Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
"""

from __future__ import annotations

import argparse
import logging
import time
from pathlib import Path
from typing import Dict

import numpy as np
import pandas as pd

from prepare_data_for_train import PREPARE_DATA_FOR_TRAIN
from ModelSaver import ModelSaver

LOG = logging.getLogger("deploy_next")
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s: %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)

def decide_action_single(p: float, neg_thr: float, pos_thr: float) -> str:
    if p >= pos_thr:
        return "BUY"
    if p <= neg_thr:
        return "SELL"
    return "NONE"

def read_last_time(csv_path: Path) -> pd.Timestamp | None:
    if not csv_path.is_file():
        return None
    df = pd.read_csv(csv_path)
    if "time" not in df.columns:
        return None
    df["time"] = pd.to_datetime(df["time"], errors="coerce")
    df.dropna(subset=["time"], inplace=True)
    if df.empty:
        return None
    return df["time"].iloc[-1]

def collect_live_paths(base: Path, symbol: str) -> Dict[str, Path]:
    return {
        "30T": base / f"{symbol}_M30_live.csv",
        "15T": base / f"{symbol}_M15_live.csv",
        "5T":  base / f"{symbol}_M5_live.csv",
        "1H":  base / f"{symbol}_H1_live.csv",
    }

def main() -> None:
    ap = argparse.ArgumentParser()
    ap.add_argument("--base-dir", default=".", type=str,
                    help="Ù¾ÙˆØ´Ù‡â€ŒÛŒ Ø­Ø§ÙˆÛŒ CSVÙ‡Ø§ÛŒ Ø®Ø§Ù… Ù…ØªØ§ØªØ±ÛŒØ¯Ø± Ùˆ best_model.pkl")
    ap.add_argument("--symbol", default="XAUUSD", type=str)
    ap.add_argument("--poll-sec", default=0.5, type=float,
                    help="ÙØ§ØµÙ„Ù‡â€ŒÛŒ Ú†Ú©â€ŒÚ©Ø±Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ *_live (Ø«Ø§Ù†ÛŒÙ‡)")
    ap.add_argument("--max-steps", default=10_000, type=int,
                    help="Ø­Ø¯Ø§Ú©Ø«Ø± ØªØ¹Ø¯Ø§Ø¯ Ø§Ø³ØªÙ¾ Ø¨Ø±Ø§ÛŒ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ")
    args = ap.parse_args()

    base = Path(args.base_dir).resolve()
    symbol = args.symbol

    # ---------- 1) Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ ----------
    saver = ModelSaver(model_dir=str(base))
    payload = saver.load_full()      # dict
    model = payload["pipeline"]      # EnsembleModel ÛŒØ§ Ù…Ø¯Ù„ ØªÚ©ÛŒ
    meta = payload

    window = int(meta["window_size"])
    neg_thr = float(meta["neg_thr"])
    pos_thr = float(meta["pos_thr"])
    train_cols = list(
        meta.get("train_window_cols")
        or meta.get("feats")
        or []
    )

    if not train_cols:
        raise ValueError("train_window_cols/feats Ø¯Ø± Ù…Ø¯Ù„ Ø°Ø®ÛŒØ±Ù‡ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")

    # Ø¢Ø³ØªØ§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡â€ŒÛŒ Ù‡Ø± Ù…Ø¯Ù„ Ø¯Ø± Ensemble (Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯)
    hyper = meta.get("hyperparams", {}) or {}
    neg_thrs = hyper.get("neg_thrs")
    pos_thrs = hyper.get("pos_thrs")

    if not neg_thrs or not pos_thrs:
        # Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø¨Ø§ Ù…Ø¯Ù„ ØªÚ©â€ŒÙ…Ø¯Ù„ÛŒ
        neg_thrs = [neg_thr]
        pos_thrs = [pos_thr]

    LOG.info(
        "Model loaded: window=%d Â· neg_thr=%.3f Â· pos_thr=%.3f Â· n_cols=%d",
        window,
        neg_thr,
        pos_thr,
        len(train_cols),
    )

    # ---------- 2) PREPARE Ø±ÙˆÛŒ CSVÙ‡Ø§ÛŒ Ø®Ø§Ù… ----------
    filepaths_raw = {
        "30T": base / f"{symbol}_M30.csv",
        "15T": base / f"{symbol}_M15.csv",
        "5T":  base / f"{symbol}_M5.csv",
        "1H":  base / f"{symbol}_H1.csv",
    }
    prep = PREPARE_DATA_FOR_TRAIN(
        filepaths={tf: str(p) for tf, p in filepaths_raw.items()},
        main_timeframe="30T",
        verbose=False,
        fast_mode=True,       # Ù„Ø§ÛŒÙˆ â†’ drift-scan Ú©Ø§Ù…Ù„ Ù„Ø§Ø²Ù… Ù†ÛŒØ³Øª
        strict_disk_feed=False,
    )

    merged = prep.load_data()
    tcol = f"{prep.main_timeframe}_time"
    merged[tcol] = pd.to_datetime(merged[tcol], errors="coerce")
    merged.sort_values(tcol, inplace=True)
    merged.reset_index(drop=True, inplace=True)

    # ---------- 3) Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ù„Ø§Ú¯ Ùˆ ÙØ§ÛŒÙ„ answer ----------
    ans_path = base / "answer.txt"
    feed_log_path = base / "deploy_X_feed_log.csv"
    pred_path = base / "deploy_predictions.csv"
    feat_tail_path = base / "deploy_X_feed_tail200.csv"

    feed_log_path.unlink(missing_ok=True)
    pred_path.unlink(missing_ok=True)
    feat_tail_path.unlink(missing_ok=True)

    live_paths = collect_live_paths(base, symbol)
    last_ts_seen: pd.Timestamp | None = None
    cover_cum = 0.0
    total_steps = 0
    traded = 0

    LOG.info("=== Deploy started (next-candle logic, safe-last-row) ===")

    for step in range(1, args.max_steps + 1):
        # --- 1) Ù…Ù†ØªØ¸Ø± *_M30_live Ø§Ø² Ú˜Ù†Ø±Ø§ØªÙˆØ± / MT4 ---
        ts_now = read_last_time(live_paths["30T"])
        if ts_now is None:
            time.sleep(args.poll_sec)
            continue

        if last_ts_seen is not None and ts_now <= last_ts_seen:
            time.sleep(args.poll_sec)
            continue

        # --- 2) Ø³Ø§Ø¨â€ŒØ³Øª Ø¯ÛŒØªØ§ ØªØ§ ts_now Ø§Ø² merged Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ´Ø¯Ù‡ ---
        sub = merged[merged[tcol] <= ts_now].copy()
        if sub.empty:
            LOG.warning("No data up to %s", ts_now)
            time.sleep(args.poll_sec)
            continue

        # --- 3) ÙÛŒÚ†Ø±Ù‡Ø§ Ø¨Ø±Ø§ÛŒ ØªÙ…Ø§Ù… Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§ ØªØ§ ts_now ---
        # Ø¯Ø± mode="predict":
        # - Ù¾Ù†Ø¬Ø±Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ú©Ø§Ù…Ù„ (Ù…Ø«Ù„ TRAIN)
        # - Ø¨Ø§ predict_drop_last=TrueØŒ Ø¢Ø®Ø±ÛŒÙ† Ú©Ù†Ø¯Ù„ (Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ù†Ø§Ù¾Ø§ÛŒØ¯Ø§Ø±) Ø­Ø°Ù Ù…ÛŒâ€ŒØ´ÙˆØ¯.
        #   Ù¾Ø³ Ø¢Ø®Ø±ÛŒÙ† Ø³Ø·Ø± X_all Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø¢Ø®Ø±ÛŒÙ† Ú©Ù†Ø¯Ù„ Â«Ú©Ø§Ù…Ù„Ø§Ù‹ Ø¨Ø³ØªÙ‡ Ø´Ø¯Ù‡Â» Ø§Ø³Øª.
        X_all, _, _, price_ser, t_idx = prep.ready(
            sub,
            window=window,
            selected_features=train_cols,   # Ù‡Ù…Ø§Ù† Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ TRAIN (Ø¨Ø¯ÙˆÙ† FS Ø¬Ø¯ÛŒØ¯)
            mode="predict",
            with_times=True,
            predict_drop_last=True,         # ğŸ”´ Ø³Ø·Ø± Ø¢Ø®Ø± Ø±Ø§ Ø­Ø°Ù Ú©Ù†
            train_drop_last=False,
        )

        if X_all.empty:
            LOG.warning("ready() returned empty at %s (after dropping last row)", ts_now)
            time.sleep(args.poll_sec)
            continue

        # --- 4) Ø¢Ø®Ø±ÛŒÙ† Ú©Ù†Ø¯Ù„ Ù¾Ø§ÛŒØ¯Ø§Ø± (t_feat) ---
        X_last = X_all.tail(1).reset_index(drop=True)
        ts_feat = pd.to_datetime(t_idx.iloc[-1])

        if ts_feat > ts_now:
            LOG.warning(
                "Time mismatch (unexpected): ts_feat=%s > ts_now=%s (after drop_last)",
                ts_feat,
                ts_now,
            )

        # --- 5) Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø§Ø­ØªÙ…Ø§Ù„ Ù„Ø§Ù†Ú¯ ---
        prob = float(model.predict_proba(X_last)[:, 1][0])

        # Ensemble Ø¨Ø§ Ø¢Ø³ØªØ§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡
        if hasattr(model, "predict_actions"):
            actions_int = model.predict_actions(X_last, neg_thrs, pos_thrs)
            a_int = int(actions_int[0])
            if a_int == 1:
                action = "BUY"
            elif a_int == 0:
                action = "SELL"
            else:
                action = "NONE"
        else:
            # Ù…Ø¯Ù„ ØªÚ©â€ŒÙ…Ø¯Ù„ÛŒ
            action = decide_action_single(prob, neg_thr, pos_thr)

        total_steps += 1
        if action != "NONE":
            traded += 1
        cover_cum = traded / float(total_steps) if total_steps > 0 else 0.0

        # --- 6) Ù†ÙˆØ´ØªÙ† answer.txt Ø¨Ø±Ø§ÛŒ Ú˜Ù†Ø±Ø§ØªÙˆØ±/MT4 ---
        try:
            ans_path.write_text(action, encoding="utf-8")
        except Exception as e:
            LOG.error("Could not write answer.txt: %s", e)

        # --- 7) Ù„Ø§Ú¯ feed (ÙÛŒÚ†Ø±Ù‡Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡â€ŒØ´Ø¯Ù‡) ---
        row_feed = {
            "timestamp": ts_feat,          # Ø²Ù…Ø§Ù† ÙÛŒÚ†Ø± (Ú©Ù†Ø¯Ù„ t)
            "timestamp_trigger": ts_now,   # Ø²Ù…Ø§Ù† ØªØ±ÛŒÚ¯Ø± (Ú©Ù†Ø¯Ù„ t ÛŒØ§ t+1ØŒ Ø·Ø¨Ù‚ Ø·Ø±Ø§Ø­ÛŒ Ú˜Ù†Ø±Ø§ØªÙˆØ±)
            "y_prob": prob,
            "action": action,
            "neg_thr": neg_thr,
            "pos_thr": pos_thr,
            "cover_cum": cover_cum,
        }
        hdr = not feed_log_path.is_file()
        pd.DataFrame([row_feed]).to_csv(
            feed_log_path,
            mode="a",
            header=hdr,
            index=False,
        )

        # --- 8) Ø°Ø®ÛŒØ±Ù‡â€ŒÛŒ ÙÛŒÚ†Ø±Ù‡Ø§ÛŒ Ù‡Ù…Ø§Ù† Ø³Ø·Ø± Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡ ---
        df_feat_row = X_last.copy()
        df_feat_row.insert(0, "timestamp_trigger", ts_now)
        df_feat_row.insert(0, "timestamp", ts_feat)
        hdr_feat = not feat_tail_path.is_file()
        pd.DataFrame(df_feat_row).to_csv(
            feat_tail_path,
            mode="a",
            header=hdr_feat,
            index=False,
        )

        # --- 9) Ù„Ø§Ú¯ predictions High-level ---
        row_pred = {
            "timestamp": ts_feat,
            "timestamp_trigger": ts_now,
            "y_prob": prob,
            "action": action,
            "cover_cum": cover_cum,
        }
        hdr2 = not pred_path.is_file()
        pd.DataFrame([row_pred]).to_csv(
            pred_path,
            mode="a",
            header=hdr2,
            index=False,
        )

        last_ts_seen = ts_now

        LOG.info(
            "[Deploy] step=%d ts_now=%s ts_feat=%s action=%s prob=%.3f cover_cum=%.3f",
            step,
            ts_now,
            ts_feat,
            action,
            prob,
            cover_cum,
        )

        time.sleep(args.poll_sec)

    LOG.info("=== Deploy finished ===")


if __name__ == "__main__":
    main()
