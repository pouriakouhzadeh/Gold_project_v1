#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
test_chimney_vs_live_no_smote.py
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ snapshot Ø¯ÙˆØ¯Ú©Ø´ (batch) â† chimney_snapshot.csv
â€¢ snapshot Ù„Ø§ÛŒÙˆ   (Ù¾Ù†Ø¬Ø±Ù‡â€ŒØ§ÛŒ) â† live_snapshot.csv
â€¢ Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„:
      â”€ Ø¯Ù‚Ù‘Øª Ùˆ F1 Ù‡Ø± Ø¯Ùˆ Ø§Ø³Ù†Ù¾â€ŒØ´Ø§Øª
      â”€ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ØŒ ØªØµÙ…ÛŒÙ…â€ŒÚ¯Ø±ÙØªÙ‡ØŒ Ø¯Ø±Ø³ØªØŒ ØºÙ„Ø·ØŒ Ø¨Ø¯ÙˆÙ† Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ (-1)
      â”€ ØªØ¹Ø¯Ø§Ø¯ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ÛŒ Ù…ØªÙØ§ÙˆØª Ø¨ÛŒÙ† Ø¯ÙˆØ¯Ú©Ø´ Ùˆ Ù„Ø§ÛŒÙˆ
      â”€ ØªØ¹Ø¯Ø§Ø¯ Ùˆ ÙÙ‡Ø±Ø³Øª ÙÛŒÚ†Ø±Ù‡Ø§ÛŒ Ù…ØªÙØ§ÙˆØª
"""

from __future__ import annotations
import argparse, logging, sys, time
from pathlib import Path
from typing import List, Dict

import joblib
import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score, f1_score
from sklearn.calibration import CalibratedClassifierCV
from sklearn.pipeline import Pipeline

# â”€â”€â”€â”€â”€â”€ Ù…Ø§Ú˜ÙˆÙ„â€ŒÙ‡Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡ â”€â”€â”€â”€â”€â”€
from prepare_data_for_train import PREPARE_DATA_FOR_TRAIN
from model_pipeline_live import ModelPipelineLive          # Ù†Ø³Ø®Ù‡Ù” Ø¨Ø¯ÙˆÙ† SMOTE

LOG = logging.getLogger("tester")
logging.basicConfig(format="%(asctime)s [%(levelname)s] %(message)s",
                    datefmt="%Y-%m-%d %H:%M:%S", level=logging.INFO)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#           build_live_estimator  (Ø¨Ø¯ÙˆÙ† SMOTE)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def build_live_estimator(fitted_pipe: Pipeline,
                         keep_calibrator: bool = True) -> ModelPipelineLive:
    scaler      = fitted_pipe.named_steps["scaler"]
    trained_clf = fitted_pipe.named_steps["classifier"]    # LR ÛŒØ§ Calibrated LR

    if isinstance(trained_clf, CalibratedClassifierCV):
        final_clf      = trained_clf
        hp_for_live    = trained_clf.estimator.get_params()
    else:
        final_clf      = trained_clf
        hp_for_live    = final_clf.get_params()

    live = ModelPipelineLive(hyperparams=hp_for_live, calibrate=False)
    live.base_pipe = Pipeline([("scaler", scaler), ("clf", final_clf)])

    if keep_calibrator and isinstance(trained_clf, CalibratedClassifierCV):
        live._calibrator = trained_clf        # pylint: disable=protected-access
    return live

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#           Snapshot utilities
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def save_snapshot(df_feat: pd.DataFrame, ts: pd.Series,
                  time_col: str, rows_lim: int, out_csv: Path):
    if rows_lim and len(df_feat) > rows_lim:
        df_feat, ts = (df.tail(rows_lim).reset_index(drop=True) for df in (df_feat, ts))
    snap = df_feat.assign(**{time_col: ts.dt.strftime("%Y-%m-%d %H:%M:%S")})
    snap.to_csv(out_csv, index=False)
    LOG.info("ğŸ“„ %s saved  (%d rows Â· %d cols)", out_csv.name, *snap.shape)

# ----------------------------------------------------------------
def chimney_snapshot(prep: PREPARE_DATA_FOR_TRAIN, merged: pd.DataFrame,
                     pipe_fit: Pipeline, window: int, feats: List[str],
                     all_cols: List[str], start: str | None, rows: int,
                     out_csv: Path):
    LOG.info("â–¶ Building CHIMNEY snapshot â€¦")
    X_raw, _, _, _ = prep.ready(merged, window=window,
                                selected_features=feats, mode="train")

    for c in all_cols:
        if c not in X_raw.columns:
            X_raw[c] = np.nan
    X_raw = X_raw.reindex(columns=all_cols).astype("float32")

    time_col = f"{prep.main_timeframe}_time"
    ts = merged[time_col].iloc[window : window + len(X_raw)].reset_index(drop=True)

    if start:
        keep = ts >= pd.Timestamp(start)
        X_raw, ts = X_raw[keep], ts[keep]

    save_snapshot(X_raw, ts, time_col, rows, out_csv)

# ----------------------------------------------------------------
def live_snapshot(prep: PREPARE_DATA_FOR_TRAIN, merged: pd.DataFrame,
                  live_est: ModelPipelineLive, window: int,
                  neg_thr: float, pos_thr: float, all_cols: List[str],
                  start: str | None, rows: int, out_csv: Path):
    LOG.info("â–¶ Running LIVE back-test â€¦")
    time_col, close_col = f"{prep.main_timeframe}_time", f"{prep.main_timeframe}_close"
    merged[time_col] = pd.to_datetime(merged[time_col])
    if start:
        merged = merged[merged[time_col] >= pd.Timestamp(start)]
    merged = merged.reset_index(drop=True)

    snaps, y_true, y_pred = [], [], []
    scaler_means = live_est.base_pipe.named_steps["scaler"].mean_

    for idx in range(window, len(merged) - 1):               # Ø¢Ø®Ø±ÛŒÙ† Ø±Ø¯ÛŒÙ label Ù†Ø¯Ø§Ø±Ø¯
        sub = merged.iloc[idx - window : idx + 1].copy().reset_index(drop=True)
        X_inc, _ = prep.ready_incremental(sub, window=window,
                                          selected_features=all_cols)
        if X_inc.empty:
            continue
        for c in all_cols:
            if c not in X_inc.columns:
                X_inc[c] = np.nan
        X_inc = X_inc[all_cols].astype("float32")
        if X_inc.isna().any().any():
            fill_means = {col: scaler_means[i] for i, col in enumerate(all_cols)}
            X_inc = X_inc.fillna(fill_means)

        proba = live_est.predict_proba(X_inc)[:, 1]
        pred  = ModelPipelineLive.apply_thresholds(proba, neg_thr, pos_thr)[0]
        ts    = merged.loc[idx, time_col]

        snaps.append(pd.Series({**{time_col: ts.strftime("%Y-%m-%d %H:%M:%S")},
                                 **{c: X_inc.iloc[0][c] for c in all_cols}}))
        y_true.append(int((merged.iloc[idx + 1][close_col] -
                           merged.iloc[idx][close_col]) > 0))
        y_pred.append(int(pred))

    snap_df = pd.DataFrame(snaps)
    save_snapshot(snap_df, pd.to_datetime(snap_df[time_col]),
                  time_col, rows, out_csv)

    return pd.Series(y_true), pd.Series(y_pred)   # Ø¬Ù‡Øª Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#        Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§Ù‰ Ø¯ÙˆØ¯Ú©Ø´ / Ù„Ø§ÛŒÙˆ + ØªØ¹Ø¯Ø§Ø¯ Ù„ÛŒØ¨Ù„ Ù…ØªÙØ§ÙˆØª
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def compute_metrics(df_snap: pd.DataFrame, merged: pd.DataFrame,
                    est, neg_thr: float, pos_thr: float,
                    all_cols: List[str]) -> Dict[str, int | float]:
    time_col, close_col = f"{prep.main_timeframe}_time", f"{prep.main_timeframe}_close"

    # true-labels
    time_map = dict(zip(merged[time_col], merged.index))
    y_true, y_pred = [], []

    # scaler MEAN Ø¬Ù‡Øª Ù¾Ø± Ú©Ø±Ø¯Ù† NaN
    scaler = est.named_steps["scaler"] if isinstance(est, Pipeline) else est.base_pipe.named_steps["scaler"]
    scaler_means = scaler.mean_

    for _, row in df_snap.iterrows():
        ts = pd.to_datetime(row[time_col])
        pos = time_map.get(ts)
        if pos is None or pos + 1 >= len(merged):
            continue                        # label Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª
        label = int((merged.iloc[pos + 1][close_col] -
                     merged.iloc[pos][close_col]) > 0)
        X = row[all_cols].to_frame().T.astype("float32")
        if X.isna().any().any():
            fill_means = {col: scaler_means[i] for i, col in enumerate(all_cols)}
            X = X.fillna(fill_means)

        proba = (est.predict_proba(X)[:, 1] if isinstance(est, Pipeline)
                 else est.predict_proba(X)[:, 1])
        pred  = ModelPipelineLive.apply_thresholds(proba, neg_thr, pos_thr)[0]

        y_true.append(label)
        y_pred.append(int(pred))

    y_true = np.array(y_true)
    y_pred = np.array(y_pred)

    decided_mask   = y_pred != -1
    n_total        = len(y_pred)
    n_decided      = int(decided_mask.sum())
    n_unpredicted  = n_total - n_decided
    n_correct      = int((y_pred[decided_mask] == y_true[decided_mask]).sum())
    n_incorrect    = n_decided - n_correct
    acc            = accuracy_score(y_true[decided_mask], y_pred[decided_mask]) if n_decided else 0.0
    f1             = f1_score     (y_true[decided_mask], y_pred[decided_mask]) if n_decided else 0.0

    return dict(total=n_total, decided=n_decided, unpred=n_unpredicted,
                correct=n_correct, incorrect=n_incorrect,
                acc=acc, f1=f1, y_pred=y_pred)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                    Diff feature snapshots
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def diff_snapshots(ref_csv: Path, live_csv: Path, diff_txt: Path,
                   abs_tol: float = 1e-6, rel_tol: float = 1e-9) -> int:
    df_ref, df_live = pd.read_csv(ref_csv), pd.read_csv(live_csv)
    time_col = next((c for c in df_ref.columns if c.endswith("_time")
                     and c in df_live.columns), None)
    if not time_col:
        LOG.error("no *_time column in common!"); return 0

    for df in (df_ref, df_live):
        df[time_col] = pd.to_datetime(df[time_col])
        df.dropna(subset=[time_col], inplace=True)
    merged = df_ref.merge(df_live, on=time_col, suffixes=("_ref", "_live"))
    diff_cols, total_diff, worst = [], 0, 0.0

    for col in [c for c in df_ref.columns if c != time_col and c in df_live.columns]:
        a, b = merged[f"{col}_ref"], merged[f"{col}_live"]
        if pd.api.types.is_numeric_dtype(a):
            abs_d = (a - b).abs()
            with np.errstate(divide="ignore", invalid="ignore"):
                rel_d = abs_d / np.maximum(a.abs(), b.abs())
            mis = (abs_d > abs_tol) & (rel_d > rel_tol)
            if mis.any():
                diff_cols.append(col); total_diff += int(mis.sum())
                worst = max(worst, float(abs_d[mis].max()))
        else:
            mis = (a.fillna("__") != b.fillna("__"))
            if mis.any():
                diff_cols.append(col); total_diff += int(mis.sum())

    diff_txt.write_text("\n".join(diff_cols) + "\n", encoding="utf-8")
    LOG.info("ğŸ” diff_cells=%d  | worst |Î”|=%.3g  | diff_columns=%d  â†’ %s",
             total_diff, worst, len(diff_cols), diff_txt.name)
    return len(diff_cols)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                      CLI & main
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def cli():
    p = argparse.ArgumentParser("Chimney vs Live tester (no-SMOTE)")
    p.add_argument("--model", default="best_model.pkl")
    p.add_argument("--data-dir", default=".")
    p.add_argument("--start")
    p.add_argument("--rows", type=int, default=2000)
    p.add_argument("--chimney-snap", default="chimney_snapshot.csv")
    p.add_argument("--live-snap",    default="live_snapshot.csv")
    p.add_argument("--diff-columns", default="diff_columns.txt")
    return p.parse_args()

# ----------------------------------------------------------------
if __name__ == "__main__":
    args = cli()
    mdl = Path(args.model).resolve()
    if not mdl.is_file():
        LOG.error("Model %s not found!", mdl); sys.exit(1)

    payload  = joblib.load(mdl)
    pipe_fit: Pipeline = payload["pipeline"]
    window   = int(payload["window_size"])
    neg_thr  = float(payload["neg_thr"])
    pos_thr  = float(payload["pos_thr"])
    feats    = payload["feats"]
    all_cols = payload["train_window_cols"]

    live_est = build_live_estimator(pipe_fit)

    csv_dir = Path(args.data_dir).resolve()
    prep = PREPARE_DATA_FOR_TRAIN(
        main_timeframe="30T",
        filepaths={
            "30T": str(csv_dir / "XAUUSD_M30.csv"),
            "15T": str(csv_dir / "XAUUSD_M15.csv"),
            "5T" : str(csv_dir / "XAUUSD_M5.csv"),
            "1H" : str(csv_dir / "XAUUSD_H1.csv"),
        },
        verbose=False,
    )

    merged_all = prep.load_data()

    # âŠ chimney snapshot
    chimney_snapshot(prep, merged_all, pipe_fit, window, feats, all_cols,
                     args.start, args.rows, Path(args.chimney_snap))

    # â‹ live snapshot + true/pred vectors
    y_true_live, y_pred_live = live_snapshot(
        prep, merged_all, live_est, window,
        neg_thr, pos_thr, all_cols,
        args.start, args.rows, Path(args.live_snap)
    )

    # âŒ diff features
    n_feat_diff = diff_snapshots(Path(args.chimney_snap),
                                 Path(args.live_snap),
                                 Path(args.diff_columns))

    # â Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ Ùˆ Ø§Ø®ØªÙ„Ø§Ù Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§
    df_chim = pd.read_csv(args.chimney_snap)
    df_live = pd.read_csv(args.live_snap)

    met_ch = compute_metrics(df_chim, merged_all, pipe_fit,
                             neg_thr, pos_thr, all_cols)
    met_lv = compute_metrics(df_live, merged_all, live_est,
                             neg_thr, pos_thr, all_cols)

    time_col = f"{prep.main_timeframe}_time"

    # ØªØ¹Ø¯Ø§Ø¯ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø§Ù†Ø¯Ú©ÛŒ Ù…ØªÙØ§ÙˆØª Ø´ÙˆØ¯Ø›
    # Ø§Ø¨ØªØ¯Ø§ Ø·ÙˆÙ„ Ù…Ø´ØªØ±Ú© Ø±Ø§ Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒÙ… Ø³Ù¾Ø³ Ø§Ø®ØªÙ„Ø§Ù Ø±Ø§ Ù…ÛŒâ€ŒØ´Ù…Ø§Ø±ÛŒÙ…
    min_len = min(len(met_ch["y_pred"]), len(met_lv["y_pred"]))
    lab_ch  = met_ch["y_pred"][:min_len]
    lab_lv  = met_lv["y_pred"][:min_len]

    # Ø§Ø®ØªÙ„Ø§ÙÙ Ø·ÙˆÙ„ Ø±Ø§ Ù‡Ù… Ø¨Ù‡â€ŒØ¹Ù†ÙˆØ§Ù† Ø¨Ø±Ú†Ø³Ø¨Ù Ù…ØªÙØ§ÙˆØª Ø­Ø³Ø§Ø¨ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
    lbl_diff = int((lab_ch != lab_lv).sum()) + abs(len(met_ch["y_pred"]) - len(met_lv["y_pred"]))


    # â”€â”€â”€â”€â”€ Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ â”€â”€â”€â”€â”€
    LOG.info("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  FINAL REPORT  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    for tag, m in [("CHIMNEY", met_ch), ("LIVE", met_lv)]:
        LOG.info("%s â” total=%d | decided=%d | correct=%d | wrong=%d | "
                 "unpred=%d | Acc=%.4f | F1=%.4f",
                 tag, m["total"], m["decided"], m["correct"],
                 m["incorrect"], m["unpred"], m["acc"], m["f1"])
    LOG.info("Label differences (Chimney â†” Live) : %d", lbl_diff)
    LOG.info("Feature columns with any diff     : %d", n_feat_diff)
    LOG.info("ğŸ‰ All done.")
