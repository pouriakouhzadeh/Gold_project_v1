#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
realtime_live_backtest_updated.py
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Ù…Ù‚Ø§ÛŒØ³Ù‡Ù” Â«Ø¯ÙˆØ¯Ú©Ø´Â» (batch) Ùˆ Â«Ù„Ø§ÛŒÙˆÂ» (incremental) Ø±ÙˆÛŒ Ù…Ø¯Ù„ Ø°Ø®ÛŒØ±Ù‡â€ŒØ´Ø¯Ù‡â€ŒÛŒ
best_model.pkl Ø¨Ø§ ØªØ¶Ù…ÛŒÙ† ÛŒÚ©Ø³Ø§Ù†â€ŒØ¨ÙˆØ¯Ù† Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§.
"""

from __future__ import annotations

import argparse, logging, sys
from pathlib import Path
from typing import List, Dict, Tuple

import joblib, numpy as np, pandas as pd
from tqdm import tqdm
from sklearn.pipeline import Pipeline
from sklearn.calibration import CalibratedClassifierCV
from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score
from sklearn.preprocessing import StandardScaler

from prepare_data_for_train import PREPARE_DATA_FOR_TRAIN
from model_pipeline_live import ModelPipelineLive          # Ù†Ø³Ø®Ù‡Ù” Ø¨Ø¯ÙˆÙ† SMOTE

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Ù„Ø§Ú¯ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LOG = logging.getLogger("tester")
logging.basicConfig(
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
    level=logging.INFO,
    handlers=[logging.StreamHandler(), logging.FileHandler("comparison_tool.log")],
)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#            1)  Ø³Ø§Ø®Øª Ù†Ø³Ø®Ù‡Ù” Ù„Ø§ÛŒÙˆÙ Ù…Ø¯Ù„Ù Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def _first_scaler(pipe: Pipeline) -> StandardScaler | None:
    """Ø§ÙˆÙ„ÛŒÙ† StandardScaler Ø¹Ù…Ù‚-Û± Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯ (Ø§Ú¯Ø± Ø¨Ø§Ø´Ø¯)."""
    for step in pipe.named_steps.values():
        if isinstance(step, StandardScaler):
            return step
    return None


def build_live_estimator(fitted_pipe: Pipeline,
                         keep_calibrator: bool = True) -> ModelPipelineLive:
    """
    Ø§Ø² Pipeline Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡ØŒ Ù†Ø³Ø®Ù‡Ù” Ù„Ø§ÛŒÙˆ Ø¨Ø¯ÙˆÙ† SMOTE Ùˆ Ø¨Ø¯ÙˆÙ† Imputer Ù…ÛŒâ€ŒØ³Ø§Ø²Ø¯.
    ØªÙ…Ø§Ù… ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡ Ø­ÙØ¸ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
    """
    LOG.info("â›  Building live estimator â€¦")

    scaler = _first_scaler(fitted_pipe)
    if scaler is None:
        raise ValueError("âŒ  No StandardScaler found inside trained pipeline.")

    trained_cls = fitted_pipe.named_steps["classifier"]
    if isinstance(trained_cls, CalibratedClassifierCV):
        final_clf   = trained_cls           # Ú©Ø§Ù„ÛŒØ¨Ø±Ù‡â€ŒØ´Ø¯Ù‡ Ø¨Ù…Ø§Ù†Ø¯
        hyperparams = trained_cls.estimator.get_params()
    else:                                   # LogisticRegression Ø®Ø§Ù„Øµ
        final_clf   = trained_cls
        hyperparams = final_clf.get_params()

    # â€•â€•â€• Ù…Ø¯Ù„ Ù„Ø§ÛŒÙˆ â†’ ÙÙ‚Ø· Â«Ø§Ø³Ú©ÛŒÙ„Ø± + Ú©Ù„Ø§Ø³ÛŒÙØ§ÛŒØ±Â» â€•â€•â€•
    live = ModelPipelineLive(hyperparams=hyperparams, calibrate=False)
    live.base_pipe = Pipeline([
        ("scaler", scaler),                 # â† ÙÛŒØª-Ø´Ø¯Ù‡
        ("clf",    final_clf),              # â† ÙÛŒØª-Ø´Ø¯Ù‡
    ])

    if keep_calibrator and isinstance(trained_cls, CalibratedClassifierCV):
        live._calibrator = trained_cls      # pylint: disable=protected-access

    LOG.info("âœ…  Live estimator ready")
    return live

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                2)  ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Snapshot
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def _ensure_columns(df: pd.DataFrame, order: List[str]) -> pd.DataFrame:
    """Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ÙÙ‚ÙˆØ¯ Ø±Ø§ Ø¨Ø§ NaN Ø§Ø¶Ø§ÙÙ‡ Ùˆ Ù…Ø±ØªØ¨ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    for c in order:
        if c not in df.columns:
            df[c] = np.nan
    return df[order]

def chimney_snapshot(prep: PREPARE_DATA_FOR_TRAIN, merged: pd.DataFrame,
                     window: int, feats: List[str], all_cols: List[str],
                     start: str | None, rows: int, out_csv: Path) -> None:

    LOG.info("â–¶ Building CHIMNEY snapshot â€¦")
    X_raw, _, _, _ = prep.ready(merged, window=window,
                                selected_features=feats, mode="train")
    X_raw = _ensure_columns(X_raw.astype("float32"), all_cols)

    tcol = f"{prep.main_timeframe}_time"
    ts = merged[tcol].iloc[window:window+len(X_raw)].reset_index(drop=True)
    if start:
        keep = ts >= pd.Timestamp(start)
        X_raw, ts = X_raw[keep], ts[keep]
    if rows and len(X_raw) > rows:
        X_raw, ts = X_raw.tail(rows), ts.tail(rows)

    X_raw[tcol] = ts.dt.strftime("%Y-%m-%d %H:%M:%S")
    X_raw.to_csv(out_csv, index=False)
    LOG.info("ğŸ“„ %s saved  (%dÃ—%d)", out_csv.name, *X_raw.shape)

# -----------------------------------------------------
def live_snapshot(prep: PREPARE_DATA_FOR_TRAIN, merged: pd.DataFrame,
                  live: ModelPipelineLive, window: int,
                  neg: float, pos: float, all_cols: List[str],
                  start: str | None, rows: int, out_csv: Path
                 ) -> Tuple[np.ndarray, np.ndarray]:

    LOG.info("â–¶ Running LIVE back-test â€¦")

    tcol = f"{prep.main_timeframe}_time"
    ccol = f"{prep.main_timeframe}_close"
    merged[tcol] = pd.to_datetime(merged[tcol])
    if start:
        merged = merged[merged[tcol] >= pd.Timestamp(start)].reset_index(drop=True)

    scaler_means = live.base_pipe.named_steps["scaler"].mean_

    snaps, y_true, y_pred = [], [], []
    rng = tqdm(range(window, len(merged)-1), desc="LIVE", unit="row", leave=False)

    for idx in rng:
        sub = merged.iloc[idx-window: idx+1].reset_index(drop=True)
        X_inc, _ = prep.ready_incremental(sub, window=window,
                                          selected_features=all_cols)
        if X_inc.empty:
            continue

        X_inc = _ensure_columns(X_inc.astype("float32"), all_cols)
        if X_inc.isna().any().any():
            X_inc = X_inc.fillna(
                {c: scaler_means[i] for i, c in enumerate(all_cols)}
            )

        proba = live.predict_proba(X_inc)[:, 1]
        pred  = ModelPipelineLive.apply_thresholds(proba, neg, pos)[0]

        snaps.append(
            pd.Series({tcol: merged.loc[idx, tcol].strftime("%Y-%m-%d %H:%M:%S"),
                       **X_inc.iloc[0].to_dict()})
        )
        # Ø¨Ø±Ú†Ø³Ø¨ Ú©Ù†Ø¯Ù„ Ø¨Ø¹Ø¯
        y_true.append(int((merged.loc[idx+1, ccol] - merged.loc[idx, ccol]) > 0))
        y_pred.append(int(pred))

        if rows and len(snaps) >= rows:
            break

    pd.DataFrame(snaps).to_csv(out_csv, index=False)
    LOG.info("ğŸ“„ %s saved  (%dÃ—%d)", out_csv.name, len(snaps), len(all_cols)+1)
    return np.array(y_true), np.array(y_pred)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                   3)  Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def compute_metrics(snap: pd.DataFrame, merged: pd.DataFrame,
                    est, neg: float, pos: float,
                    all_cols: List[str]) -> Dict[str, float | int | np.ndarray]:

    tcol = next(c for c in snap.columns if c.endswith("_time"))
    ccol = tcol.replace("_time", "_close")
    time_map = dict(zip(merged[tcol], merged.index))

    scaler = (est.named_steps["scaler"]
              if isinstance(est, Pipeline)
              else est.base_pipe.named_steps["scaler"])
    means = scaler.mean_

    yt, yp = [], []
    for _, row in snap.iterrows():
        ts = pd.to_datetime(row[tcol]); pos_idx = time_map.get(ts)
        if pos_idx is None or pos_idx+1 >= len(merged): continue

        label = int((merged.loc[pos_idx+1, ccol] - merged.loc[pos_idx, ccol]) > 0)
        X = _ensure_columns(row[all_cols].to_frame().T.astype("float32"), all_cols)
        if X.isna().any().any():
            X = X.fillna({c: means[i] for i, c in enumerate(all_cols)})

        p = est.predict_proba(X)[:, 1] if not isinstance(est, Pipeline) \
            else est.predict_proba(X)[:, 1]
        pr = ModelPipelineLive.apply_thresholds(p, neg, pos)[0]

        yt.append(label); yp.append(int(pr))

    yt, yp = np.array(yt), np.array(yp)
    mask = yp != -1
    return dict(
        total=len(yp),
        conf=float(mask.mean()) if len(mask) else 0.0,
        acc=accuracy_score(yt[mask], yp[mask]) if mask.any() else 0.0,
        balacc=balanced_accuracy_score(yt[mask], yp[mask]) if mask.any() else 0.0,
        f1=f1_score(yt[mask], yp[mask]) if mask.any() else 0.0,
        correct=int(((yp == yt) & mask).sum()),
        incorrect=int((mask & (yp != yt)).sum()),
        unpred=int((~mask).sum()),
        y_pred=yp,
    )

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                      4)  CLI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def cli():
    p = argparse.ArgumentParser("Chimney vs Live (no-SMOTE)")
    p.add_argument("--model",     default="best_model.pkl")
    p.add_argument("--data-dir",  default=".")
    p.add_argument("--start")
    p.add_argument("--rows",      type=int, default=2000)
    p.add_argument("--chimney",   default="chimney_snapshot.csv")
    p.add_argument("--live",      default="live_snapshot.csv")
    return p.parse_args()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                        5)  MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if __name__ == "__main__":
    args = cli()

    # ---------- Load artefacts ----------
    payload = joblib.load(args.model)
    pipe_fit: Pipeline = payload["pipeline"]
    window   = int(payload["window_size"])
    neg_thr  = float(payload["neg_thr"])
    pos_thr  = float(payload["pos_thr"])
    feats    = payload["feats"]
    all_cols = payload["train_window_cols"]

    live_est = build_live_estimator(pipe_fit)

    # ---------- Load data ----------
    csv_dir = Path(args.data_dir).resolve()
    prep = PREPARE_DATA_FOR_TRAIN(
        main_timeframe="30T",
        filepaths={
            "30T": str(csv_dir / "XAUUSD_M30.csv"),
            "15T": str(csv_dir / "XAUUSD_M15.csv"),
            "5T" : str(csv_dir / "XAUUSD_M5.csv"),
            "1H" : str(csv_dir / "XAUUSD_H1.csv"),
        },
        verbose=False,
    )
    merged = prep.load_data()

    # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª
    N_LAST = 4000
    if len(merged) > N_LAST + window:
        merged = merged.tail(N_LAST + window).reset_index(drop=True)
        LOG.info("âš¡ Back-test limited to last %d rows (+window)", N_LAST)

    # ---------- Snapshots ----------
    chimney_snapshot(prep, merged, window, feats, all_cols,
                     args.start, args.rows, Path(args.chimney))
    live_snapshot   (prep, merged, live_est, window,
                     neg_thr, pos_thr, all_cols,
                     args.start, args.rows, Path(args.live))

    # ---------- Metrics ----------
    met_ch = compute_metrics(pd.read_csv(args.chimney), merged,
                             pipe_fit, neg_thr, pos_thr, all_cols)
    met_lv = compute_metrics(pd.read_csv(args.live), merged,
                             live_est, neg_thr, pos_thr, all_cols)

    # ---------- Report ----------
    diff_labels = int((met_ch["y_pred"][:min(len(met_ch["y_pred"]),
                                            len(met_lv["y_pred"]))] !=
                       met_lv["y_pred"][:min(len(met_ch["y_pred"]),
                                             len(met_lv["y_pred"]))]).sum())

    LOG.info("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  FINAL REPORT  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    for tag, m in [("CHIMNEY", met_ch), ("LIVE", met_lv)]:
        LOG.info("%s â” size=%d | conf=%.2f | Acc=%.4f | BalAcc=%.4f | "
                 "F1=%.4f | correct=%d | wrong=%d | unpred=%d",
                 tag, m["total"], m["conf"], m["acc"], m["balacc"],
                 m["f1"], m["correct"], m["incorrect"], m["unpred"])
    LOG.info("Label differences (Chimney â†” Live): %d", diff_labels)
    LOG.info("ğŸ‰ All done.")
