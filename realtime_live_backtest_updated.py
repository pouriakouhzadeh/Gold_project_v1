#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
test_chimney_vs_live_no_smote.py
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ Snapshot Ø¯ÙˆØ¯Ú©Ø´ (batch) â† chimney_snapshot.csv
â€¢ Snapshot Ù„Ø§ÛŒÙˆ (Ù¾Ù†Ø¬Ø±Ù‡â€ŒØ§ÛŒ) â† live_snapshot.csv
â€¢ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ùˆ Ú¯Ø²Ø§Ø±Ø´:
      - ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ø³Ù„ÙˆÙ„â€ŒÙ‡Ø§ÛŒ Ù…ØªÙØ§ÙˆØª
      - Ø¨Ø¯ØªØ±ÛŒÙ† |Î”| Ø¹Ø¯Ø¯ÛŒ
      - Ø°Ø®ÛŒØ±Ù‡Ù” Ù†Ø§Ù… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø§Ø®ØªÙ„Ø§Ù Ø¯Ø§Ø±Ù†Ø¯ â†’ diff_columns.txt
"""

from __future__ import annotations
import argparse, logging, sys, time
from pathlib import Path
from typing import Dict, List

import joblib
import numpy as np
import pandas as pd
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, f1_score
from sklearn.calibration import CalibratedClassifierCV   
from sklearn.pipeline import Pipeline

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Ù…Ø§Ú˜ÙˆÙ„â€ŒÙ‡Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡ (Ø¯Ø± Ù‡Ù…Ø§Ù† ÙÙˆÙ„Ø¯Ø±) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from prepare_data_for_train import PREPARE_DATA_FOR_TRAIN
from model_pipeline_live import ModelPipelineLive          # â† Ù†Ø³Ø®Ù‡Ù” Ø¨Ø¯ÙˆÙ† SMOTE

LOG = logging.getLogger("tester")
logging.basicConfig(format="%(asctime)s [%(levelname)s] %(message)s",
                    datefmt="%Y-%m-%d %H:%M:%S",
                    level=logging.INFO)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#          Helpers
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ----------------------------------------------------------------------
# build_live_estimator  (Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ù†Ø³Ø®Ù‡Ù” Ù‚Ø¨Ù„ÛŒ)
# ----------------------------------------------------------------------
# ----------------------------------------------------------------------
# build_live_estimator  âŸ¶  Ù†Ø³Ø®Ù‡Ù” Ø¨Ø¯ÙˆÙ†-SMOTEØŒ Ø§ÛŒÙ…Ù† Ùˆ Ø¨Ø¯ÙˆÙ† Ø®Ø·Ø§ÛŒ NotFitted
# ----------------------------------------------------------------------
def build_live_estimator(fitted_pipe: Pipeline,
                         keep_calibrator: bool = True
                         ) -> ModelPipelineLive:
    """
    ÙˆØ±ÙˆØ¯ÛŒ
    -----
    fitted_pipe : Pipeline
        Ø¯ÙˆØ¯Ú©Ø´Ù Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡ (scaler â†’ SMOTE â†’ classifier).
    keep_calibrator : bool
        Ø§Ú¯Ø± True Ø¨Ø§Ø´Ø¯ Ùˆ classifier Ø§Ø² Ù†ÙˆØ¹ CalibratedClassifierCV Ø¨Ø§Ø´Ø¯ØŒ
        Ù‡Ù…Ø§Ù† Ú©Ø§Ù„ÛŒØ¨Ø±Ø§ØªÙˆØ±Ù ÙÛŒØª-Ø´Ø¯Ù‡ Ø±Ø§ Ø¨Ù‡ Ù„Ø§ÛŒÙˆ Ù…Ù†ØªÙ‚Ù„ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ….

    Ø®Ø±ÙˆØ¬ÛŒ
    -----
    ModelPipelineLive
        ÛŒÚ© Ù…Ø¯Ù„Ù Ù„Ø§ÛŒÙˆ Ú©Ù‡ ØªØ±ØªÛŒØ¨ ØµØ­ÛŒØ­ Â«Ø§Ø³Ú©ÛŒÙ„Ø± â‡¢ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯Â» Ø±Ø§ Ø­ÙØ¸ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
        Ùˆ Ø¯Ø± Ù…Ø±Ø­Ù„Ù‡Ù” Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù‡ÛŒÚ† Ø§Ø«Ø±ÛŒ Ø§Ø² SMOTE Ù†Ø¯Ø§Ø±Ø¯.
    """

    # 1) Ø§Ø¬Ø²Ø§ÛŒ Ù„Ø§Ø²Ù… Ø±Ø§ Ø§Ø² Ø¯ÙˆØ¯Ú©Ø´ Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡ Ø¨ÛŒØ±ÙˆÙ† Ø¨Ú©Ø´
    scaler = fitted_pipe.named_steps["scaler"]
    cls_trained = fitted_pipe.named_steps["classifier"]     # LR ÛŒØ§ Calibrated LR

    # Ø§Ú¯Ø± classifier ÛŒÚ© CalibratedClassifierCV Ø¨Ø§Ø´Ø¯ Ù‡Ù…Ø§Ù† Ø±Ø§ Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±ÛŒÙ…
    if isinstance(cls_trained, CalibratedClassifierCV):
        final_clf       = cls_trained          # Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø¨Ù‡â€ŒØ¹Ù†ÙˆØ§Ù† clf Ù…ÛŒâ€ŒØ±ÙˆØ¯
        hyper_for_live  = cls_trained.estimator.get_params()
    else:
        final_clf       = cls_trained          # LogisticRegression ÙÛŒØª-Ø´Ø¯Ù‡
        hyper_for_live  = final_clf.get_params()

    # 2) ÛŒÚ© Ø§Ø¨Ø¬Ú©Øª  ModelPipelineLive  Ù…ÛŒâ€ŒØ³Ø§Ø²ÛŒÙ… (Ø¨Ø¯ÙˆÙ† SMOTE)
    live = ModelPipelineLive(
        hyperparams=hyper_for_live,
        calibrate=False        # Ú©Ø§Ù„ÛŒØ¨Ø±Ù‡ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ù…Ù†ØªÙ‚Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯ (Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²)
    )

    # 3) Pipeline Ù„Ø§ÛŒÙˆ =  scaler  âœ  (calibrator ÛŒØ§ LR)
    #    Ø¯ÛŒÚ¯Ø± Ù†ÛŒØ§Ø²ÛŒ Ù†ÛŒØ³Øª base_pipe Ù‚Ø¯ÛŒÙ…ÛŒ Ø±Ø§ Ù„Ù…Ø³ Ú©Ù†ÛŒÙ…Ø› Ù…Ø³ØªÙ‚ÛŒÙ… Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
    live.base_pipe = Pipeline([
        ("scaler", scaler),
        ("clf",    final_clf),
    ])

    # 4) Ø§Ú¯Ø± classifierØŒ ÛŒÚ© CalibratedClassifierCV Ø¨ÙˆØ¯ Ùˆ Ú©Ø§Ø±Ø¨Ø± Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡Ø¯
    #    Ù‡Ù…Ø§Ù† Ú©Ø§Ù„ÛŒØ¨Ø±Ø§ØªÙˆØ± Ø±Ø§ Ø­ÙØ¸ Ú©Ù†Ø¯ØŒ Ø¢Ù† Ø±Ø§ ØªØ²Ø±ÛŒÙ‚ Ú©Ù†
    if keep_calibrator and isinstance(cls_trained, CalibratedClassifierCV):
        live._calibrator = cls_trained        # pylint: disable=protected-access

    return live

def save_snapshot(df_feat: pd.DataFrame,
                  ts: pd.Series,
                  time_col: str,
                  rows_lim: int,
                  out_csv: Path):
    if rows_lim and len(df_feat) > rows_lim:
        df_feat, ts = (df.tail(rows_lim).reset_index(drop=True) for df in (df_feat, ts))
    snap = df_feat.assign(**{time_col: ts.dt.strftime("%Y-%m-%d %H:%M:%S")})
    snap.to_csv(out_csv, index=False)
    LOG.info("ğŸ“„ %s saved (%d rows, %d cols)", out_csv.name, *snap.shape)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#          Build chimney snapshot  (batch)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def chimney_snapshot(prep: PREPARE_DATA_FOR_TRAIN,
                     window: int,
                     feats: List[str],
                     all_cols: List[str],
                     start: str | None,
                     rows: int,
                     out_csv: Path):
    LOG.info("â–¶ Building CHIMNEY snapshot â€¦")
    merged = prep.load_data()
    X_raw, _, _, _ = prep.ready(merged, window=window,
                                selected_features=feats, mode="train")

    # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ØªÙ…Ø§Ù… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ùˆ ØªØ±ØªÛŒØ¨
    for c in all_cols:
        if c not in X_raw.columns:
            X_raw[c] = np.nan
    X_raw = X_raw.reindex(columns=all_cols).astype("float32")

    time_col = f"{prep.main_timeframe}_time"
    ts = merged[time_col].iloc[window:window+len(X_raw)].reset_index(drop=True)

    if start:
        keep = ts >= pd.Timestamp(start)
        X_raw, ts = X_raw[keep], ts[keep]

    save_snapshot(X_raw, ts, time_col, rows, out_csv)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#          Live / back-test snapshot  (no-SMOTE pipeline)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def live_snapshot(prep: PREPARE_DATA_FOR_TRAIN,
                  merged: pd.DataFrame,
                  live_est,
                  window: int,
                  neg_thr: float,
                  pos_thr: float,
                  all_cols: List[str],
                  start: str | None,
                  rows: int,
                  out_csv: Path):

    LOG.info("â–¶ Running LIVE back-test â€¦")
    time_col  = f"{prep.main_timeframe}_time"
    close_col = f"{prep.main_timeframe}_close"

    merged[time_col] = pd.to_datetime(merged[time_col])
    if start:
        merged = merged[merged[time_col] >= pd.Timestamp(start)].reset_index(drop=True)

    snaps, y_true, y_pred = [], [], []

    for idx in range(window, len(merged)-1):      # -1 â‡’ future label Ù…ÙˆØ¬ÙˆØ¯
        sub = merged.iloc[idx-window:idx+1].copy().reset_index(drop=True)
        X_inc, _ = prep.ready_incremental(sub, window=window,
                                          selected_features=all_cols)
        if X_inc.empty:
            continue

        for c in all_cols:
            if c not in X_inc.columns:
                X_inc[c] = np.nan
        X_inc = X_inc[all_cols].astype("float32")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # NEW â–¸ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†ÛŒ NaN-Ù‡Ø§ Ø¨Ø§ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø¢Ù…ÙˆØ²Ø´ (scaler.mean_)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if X_inc.isna().any().any():
            scaler_means = live_est.base_pipe.named_steps["scaler"].mean_
            mean_dict = {col: scaler_means[i] for i, col in enumerate(all_cols)}
            X_inc = X_inc.fillna(mean_dict)

        proba = live_est.predict_proba(X_inc)[:, 1]
        pred  = ModelPipelineLive.apply_thresholds(proba, neg_thr, pos_thr)[0]

        ts    = merged.loc[idx, time_col]
        snaps.append(pd.Series({**{time_col: ts.strftime("%Y-%m-%d %H:%M:%S")},
                                 **{c: X_inc.iloc[0][c] for c in all_cols}}))
        # real label
        y_true.append(int((merged.loc[idx+1, close_col] - merged.loc[idx, close_col]) > 0))
        y_pred.append(int(pred))

    snap_df = pd.DataFrame(snaps)
    save_snapshot(snap_df, pd.to_datetime(snap_df[time_col]), time_col, rows, out_csv)

    # Ù…ØªØ±ÛŒÚ© Ø±ÙˆÙ‰ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒ ØªØµÙ…ÛŒÙ…
    mask = np.array(y_pred) != -1
    if mask.any():
        acc = accuracy_score(np.array(y_true)[mask], np.array(y_pred)[mask])
        f1  = f1_score(np.array(y_true)[mask],  np.array(y_pred)[mask])
        LOG.info("LIVE decided=%d  |  Acc=%.4f  F1=%.4f",
                 int(mask.sum()), acc, f1)
    else:
        LOG.warning("âš  No decided rows in LIVE snapshot")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#          Snapshot diff & report
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def diff_snapshots(ref_csv: Path,
                   live_csv: Path,
                   diff_txt: Path,
                   abs_tol: float = 1e-6,
                   rel_tol: float = 1e-9) -> None:
    LOG.info("â–¶ Comparing snapshots â€¦")
    df_ref  = pd.read_csv(ref_csv,  low_memory=False)
    df_live = pd.read_csv(live_csv, low_memory=False)

    # ØªØ´Ø®ÛŒØµ Ø³ØªÙˆÙ† Ø²Ù…Ø§Ù† (Ø§ÙˆÙ„ÛŒÙ† Ø³ØªÙˆÙ†ÛŒ Ú©Ù‡ Ø¨Ø§ _time ØªÙ…Ø§Ù… Ù…Ù‰â€ŒØ´ÙˆØ¯ Ùˆ Ø¯Ø± Ù‡Ø± Ø¯Ùˆ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯)
    time_col = next((c for c in df_ref.columns if c.endswith("_time") and c in df_live.columns), None)
    if not time_col:
        LOG.error("Could not find common *_time column"); return

    for df in (df_ref, df_live):
        df[time_col] = pd.to_datetime(df[time_col])
        df.dropna(subset=[time_col], inplace=True)
        df.drop_duplicates(subset=[time_col], keep="last", inplace=True)

    merged = df_ref.merge(df_live, on=time_col, how="inner", suffixes=("_ref", "_live"))
    if merged.empty:
        LOG.error("No overlapping timestamps between snapshots!"); return

    diff_cols, total_diff, worst_abs = [], 0, 0.0

    common_cols = [c for c in df_ref.columns if c != time_col and c in df_live.columns]
    for col in common_cols:
        a = merged[f"{col}_ref"]
        b = merged[f"{col}_live"]

        if pd.api.types.is_numeric_dtype(a):
            abs_diff = (a - b).abs()
            with np.errstate(divide="ignore", invalid="ignore"):
                rel_diff = abs_diff / np.maximum(a.abs(), b.abs())
            mis = (abs_diff > abs_tol) & (rel_diff > rel_tol)
            if mis.any():
                diff_cols.append(col)
                total_diff += int(mis.sum())
                worst_abs = max(worst_abs, float(abs_diff[mis].max()))
        else:
            mis = (a.fillna("__") != b.fillna("__"))
            if mis.any():
                diff_cols.append(col)
                total_diff += int(mis.sum())

    # Ù†ÙˆØ´ØªÙ† Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ØªÙØ§ÙˆØª
    diff_txt.write_text("\n".join(diff_cols) + "\n", encoding="utf-8")
    LOG.info("ğŸ” diff finished | diff_cells=%d | worst |Î”|=%.3g | columns listed â†’ %s",
             total_diff, worst_abs, diff_txt.name)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#          CLI & Main
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def cli():
    p = argparse.ArgumentParser("Chimney vs Live tester (no-SMOTE) + diff")
    p.add_argument("--model", default="best_model.pkl")
    p.add_argument("--data-dir", default=".")
    p.add_argument("--start", help="e.g. '2025-01-01 00:00'")
    p.add_argument("--rows", type=int, default=2000)
    p.add_argument("--chimney-snap", default="chimney_snapshot.csv")
    p.add_argument("--live-snap",    default="live_snapshot.csv")
    p.add_argument("--diff-columns", default="diff_columns.txt")
    return p.parse_args()


def main():
    args = cli()
    mdl_path = Path(args.model).resolve()
    if not mdl_path.is_file():
        LOG.error("Model %s not found", mdl_path); sys.exit(1)

    payload   = joblib.load(mdl_path)
    pipe_fit  : Pipeline = payload["pipeline"]
    window    : int      = int(payload["window_size"])
    neg_thr   : float    = float(payload["neg_thr"])
    pos_thr   : float    = float(payload["pos_thr"])
    feats     : List[str]= payload["feats"]
    all_cols  : List[str]= payload["train_window_cols"]

    live_est = build_live_estimator(pipe_fit)

    csv_dir = Path(args.data_dir).resolve()
    prep = PREPARE_DATA_FOR_TRAIN(
        main_timeframe="30T",
        filepaths={
            "30T": str(csv_dir / "XAUUSD_M30.csv"),
            "15T": str(csv_dir / "XAUUSD_M15.csv"),
            "5T" : str(csv_dir / "XAUUSD_M5.csv"),
            "1H" : str(csv_dir / "XAUUSD_H1.csv"),
        },
        verbose=False,
    )

    # â¶ Ø¯ÙˆØ¯Ú©Ø´
    chimney_snapshot(prep, window, feats, all_cols,
                     args.start, args.rows, Path(args.chimney_snap))

    # â· Ù„Ø§ÛŒÙˆ
    merged_all = prep.load_data()
    live_snapshot(prep, merged_all, live_est, window,
                  neg_thr, pos_thr, all_cols,
                  args.start, args.rows, Path(args.live_snap))

    # â¸ Ù…Ù‚Ø§ÛŒØ³Ù‡
    diff_snapshots(Path(args.chimney_snap),
                   Path(args.live_snap),
                   Path(args.diff_columns))

    LOG.info("ğŸ‰ All done.")


if __name__ == "__main__":
    main()
